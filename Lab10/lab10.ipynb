{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: 25/12 ([CET](https://www.timeanddate.com/time/zones/cet))\n",
    "* Reviews: 06/01 ([CET](https://en.wikipedia.org/wiki/Sol_Invictus))\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see it this way: picking 3 numbers whose sum is 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice, random, randint\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(sum(c)==15 for c in combinations({1,2,3,4,5,6},3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "State= namedtuple('State',['x','o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGIC=[2,7,6,\n",
    "       9,5,1,\n",
    "       4,3,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win(elements):\n",
    "    \"\"\" Checks if elements is winning\"\"\"\n",
    "    return any(sum(c)==15 for c in combinations(elements,3))\n",
    "\n",
    "def state_value(pos:State):\n",
    "    \"\"\"Evaluate position: +1 first player wins\"\"\"\n",
    "    if win(pos.x):\n",
    "        return 1\n",
    "    elif win(pos.o):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_board(pos):\n",
    "    \"\"\" Nicely prints the board\"\"\"\n",
    "    for r in range(3):\n",
    "        for c in range(3):\n",
    "            index=r*3+c\n",
    "            if MAGIC[index] in pos.x:\n",
    "                print('X', end='')\n",
    "            elif MAGIC[index] in pos.o:\n",
    "                print('O', end='')\n",
    "            else:\n",
    "                print('-', end='')\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_game():\n",
    "    #starts with an empty position and keeps on adding one element in both side until someone wins\n",
    "    trajectory=list()\n",
    "    state=State(set(), set())\n",
    "    available=set(range(1,9+1))\n",
    "    while True:\n",
    "        \n",
    "        x= choice(list(available))\n",
    "        state.x.add(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x) \n",
    "        \n",
    "        \n",
    "        if(win(state.x)) or not available:\n",
    "            break\n",
    "               \n",
    "        o = choice(list(available))\n",
    "        state.o.add(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "        if(win(state.o)):\n",
    "            break\n",
    "\n",
    "    return trajectory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer:\n",
    "    def __init__(self, symbol) -> None:\n",
    "        self._symbol=symbol\n",
    "        \n",
    "    @property\n",
    "    def symbol(self)-> int:\n",
    "        return self._symbol\n",
    "    \n",
    "    def move(self,available_moves, state=None):\n",
    "        return choice(list(available_moves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, symbol) -> None:\n",
    "        self._symbol=symbol\n",
    "        self._dict_moves=defaultdict(float)\n",
    "        self._winning_games=0\n",
    "\n",
    "    @property\n",
    "    def symbol(self)-> int:\n",
    "        return self._symbol\n",
    "    \n",
    "    @property\n",
    "    def dict_moves(self)-> int:\n",
    "        return self._dict_moves\n",
    "    \n",
    "    def move(self,available_moves, state)->int:\n",
    "\n",
    "        if random()<0.05:\n",
    "            best_move = choice(list(available_moves))\n",
    "            temp_state = deepcopy(state) \n",
    "            temp_state.x.add(best_move)\n",
    "            if (frozenset(state.x), frozenset(state.o)) not in self.dict_moves.keys():\n",
    "                self.dict_moves[(frozenset(temp_state.x), frozenset(temp_state.o))]=0.001\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            #keys= [k for k in self.dict_moves.keys() if (k[1] == state.o and len(k[0])==len(state.x)+1 )]\n",
    "            keys= [k for k in self.dict_moves.keys() if (k[1] == state.o and k[0]==state.x )]\n",
    "\n",
    "            if keys:\n",
    "                #new_state = sorted(keys, key=lambda k: self.dict_moves[k], reverse=True)\n",
    "\n",
    "                \"\"\" best_move=list(new_state[0][0]-state.x)[0]\n",
    "\n",
    "                while(best_move not in available_moves and i<len(new_state)):\n",
    "\n",
    "                    best_move=list(new_state[i][0]-state.x)[0]\n",
    "                    #print(best_move)\n",
    "                    i+=1\n",
    "                    if (best_move not in available_moves):\n",
    "                        best_move=None\n",
    "                \n",
    "                if(best_move is None):\n",
    "                    best_move = choice(list(available_moves))\n",
    "                    state.x.add(best_move)\n",
    "                    \n",
    "                    self.dict_moves[(frozenset(state.x), frozenset(state.o))]=0.01\n",
    "                print(\"best move\", best_move)\n",
    "                \"\"\"  \n",
    "                best_move = None\n",
    "                max_value = float('-inf')\n",
    "\n",
    "                for move in available_moves:\n",
    "                    temp_state = deepcopy(state)  \n",
    "                    temp_state.x.add(move)\n",
    "                    hashable_state = (frozenset(temp_state.x), frozenset(temp_state.o))\n",
    "\n",
    "                    if hashable_state in self.dict_moves.keys():\n",
    "                        move_value = self.dict_moves[hashable_state]\n",
    "                        if move_value > max_value:\n",
    "                            max_value = move_value\n",
    "                            best_move = move\n",
    "\n",
    "                if best_move is None:\n",
    "                    best_move = choice(list(available_moves))\n",
    "                    #state.x.add(best_move)\n",
    "                    temp_state = deepcopy(state) \n",
    "                    temp_state.x.add(best_move)\n",
    "                    self.dict_moves[(frozenset(temp_state.x), frozenset(temp_state.o))]=0.001\n",
    "            else:\n",
    "                best_move = choice(list(available_moves))\n",
    "                #state.x.add(best_move)\n",
    "                temp_state = deepcopy(state) \n",
    "                temp_state.x.add(best_move)\n",
    "                self.dict_moves[(frozenset(temp_state.x), frozenset(temp_state.o))]=0.001\n",
    "        return best_move\n",
    "    \n",
    "    def add_winning(self):\n",
    "        self._winning_games+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_game_1(p1,p2):\n",
    "    \n",
    "    trajectory=list()\n",
    "    state=State(set(), set())\n",
    "    available=set(range(1,9+1))\n",
    "\n",
    "\n",
    "    players=[p1,p2]\n",
    "    index=choice([0,1])\n",
    "    #index=1\n",
    "    #index=0\n",
    "    while True:\n",
    "        \n",
    "        current_player=players[index]\n",
    "\n",
    "        move=current_player.move(list(available),state)\n",
    "\n",
    "        if(current_player.symbol == -1):\n",
    "            state.o.add(move)\n",
    "            trajectory.append(deepcopy(state))\n",
    "            available.remove(move) \n",
    "            if(win(state.o)) or not available:\n",
    "                break\n",
    "        \n",
    "        else:\n",
    "            state.x.add(move)\n",
    "            trajectory.append(deepcopy(state))\n",
    "            available.remove(move) \n",
    "            if(win(state.x)) or not available:\n",
    "                current_player.add_winning()\n",
    "                break\n",
    "    \n",
    "        index=1-index\n",
    "\n",
    "    return trajectory\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:54<00:00, 436.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning percentage of the agent  74.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "value_dictionary=defaultdict(float)\n",
    "epsilon=0.001\n",
    "\n",
    "\n",
    "#o\n",
    "p1=RandomPlayer(-1)\n",
    "#x\n",
    "p2=Agent(1)\n",
    "\n",
    "num_iterations=50_000\n",
    "\n",
    "for steps in tqdm(range(num_iterations)):\n",
    "    trajectory=random_game_1(p1,p2)\n",
    "   \n",
    "    # i compute the final reward\n",
    "    final_reward=state_value(trajectory[-1])\n",
    "    #print(final_reward)\n",
    "    #update all the state according to this reward\n",
    "    for s in trajectory:\n",
    "        hashable_state=(frozenset(s.x),frozenset(s.o))\n",
    "        p2.dict_moves[hashable_state]= p2.dict_moves[hashable_state]+epsilon*(final_reward-p2.dict_moves[hashable_state])\n",
    "\n",
    "\n",
    "print(\"Winning percentage of the agent \",p2._winning_games/num_iterations*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((frozenset({5}), frozenset({3})), 0.5875470604494527),\n",
       " ((frozenset({5}), frozenset({1})), 0.5459017636752646),\n",
       " ((frozenset({5}), frozenset({8})), 0.5434493075985732),\n",
       " ((frozenset(), frozenset({1})), 0.5374438690564269),\n",
       " ((frozenset(), frozenset({3})), 0.5287986272934934),\n",
       " ((frozenset(), frozenset({8})), 0.48199871248632936),\n",
       " ((frozenset({5}), frozenset({6})), 0.4758250132154504),\n",
       " ((frozenset({2}), frozenset({4})), 0.47425306526850397),\n",
       " ((frozenset({4}), frozenset({9})), 0.4567156884306328),\n",
       " ((frozenset({6}), frozenset({7})), 0.4463894541918245)]"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(p2.dict_moves.items(), key=lambda e: e[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets aren't hashable but frozen sets are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=frozenset({2,3,4})\n",
    "y={x:'yess'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
